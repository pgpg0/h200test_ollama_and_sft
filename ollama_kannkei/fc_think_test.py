import json
import re
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
from tqdm import tqdm
import time

# --- è¨­å®šé …ç›® ---
# â˜… å…¥åŠ›ã¨å‡ºåŠ›ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®š
INPUT_JSONL_PATH = Path('/home/ubuntu/client/Data_azami/code/synthetic_data_output/fc_data_format/converted_truly_final_1_namiuchi_ver2.jsonl')
OUTPUT_JSONL_PATH = Path('/home/ubuntu/client/Data_azami/code/synthetic_data_output/with_think_data/generated_thinking_new_format.jsonl')

# â˜… ãƒ¢ãƒ‡ãƒ«ã¨APIè¨­å®š
MODEL_NAME = "mistral-small"
MAX_ATTEMPTS = 3
NUM_GPUS = 8
BASE_PORT = 11435

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ---
# tool_callså½¢å¼ã«å¯¾å¿œã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
THINKING_GENERATION_PROMPT_TEMPLATE = """
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ï¼ˆquestionï¼‰ã¨ã€ãã®è³ªå•ã«å›ç­”ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãƒªã‚¹ãƒˆï¼ˆanswerï¼‰ãŒæç¤ºã•ã‚Œã¾ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’é”æˆã™ã‚‹ãŸã‚ã«ã€ãªãœãã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ï¼ˆanswerï¼‰ãŒå¿…è¦ãªã®ã‹ã€ãã®é †åºã§å‘¼ã³å‡ºã™å¿…è¦ãŒã‚ã‚‹ã®ã‹ã‚’è«–ç†çš„ã«èª¬æ˜ã™ã‚‹æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ï¼ˆthinkingï¼‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

# åˆ¶ç´„
- å„ãƒ„ãƒ¼ãƒ«ã®å½¹å‰²ã‚„ç›®çš„ã‚’ä¸­å¿ƒã«ã€ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
- å¿…ãšæ—¥æœ¬èªã§ã€è‡ªç„¶ã§åˆ†ã‹ã‚Šã‚„ã™ã„æ–‡ç« ã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
- thinkingã®å‡ºåŠ›ã®ã¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚ä½™è¨ˆãªæ¥é ­è¾ï¼ˆã€Œthinking:ã€ãªã©ï¼‰ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚

# fewshotä¾‹
## ä¾‹1
### question
æ˜æ—¥ã®åˆå¾Œ3æ™‚ã«å¤§å‹ã‚¹ãƒ¼ãƒ‘ãƒ¼ã¸ã®è²·ã„å‡ºã—ã«è¡Œãäºˆå®šã§ã™ã€‚å®¶ã‹ã‚‰æœ€ã‚‚è¿‘ã„å¤§å‹ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚’æ¤œç´¢ã—ã€ãã®å ´æ‰€ã¾ã§ã®é“é †ã¨æ‰€è¦æ™‚é–“ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ã¾ãŸã€ãã®ã‚¹ãƒ¼ãƒ‘ãƒ¼ã®å–¶æ¥­æ™‚é–“ã‚’ç¢ºèªã—ã¦ã€3æ™‚ã«è¡Œã‘ã‚‹ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚
### answer
[
  {{
    "name": "maps_search_places",
    "arguments": "{{\\"query\\": \\"å¤§å‹ã‚¹ãƒ¼ãƒ‘ãƒ¼\\"}}"
  }},
  {{
    "name": "maps_place_details",
    "arguments": "{{\\"place_id\\": \\"maps_search_placesã®çµæœã‹ã‚‰å–å¾—\\"}}"
  }},
  {{
    "name": "maps_directions",
    "arguments": "{{\\"origin\\": \\"å®¶ã®ä½æ‰€\\", \\"destination\\": \\"maps_place_detailsã®çµæœã‹ã‚‰å–å¾—\\"}}"
  }}
]
### thinking
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ç‰¹å®šã®æ—¥æ™‚ã«è²·ã„ç‰©ã«è¡ŒããŸã‚ã®è¨ˆç”»ã‚’ç«‹ã¦ãŸã„ã¨è€ƒãˆã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’æ®µéšçš„ã«å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
1. **å ´æ‰€ã®æ¤œç´¢:** ã¾ãšã€ã€Œå¤§å‹ã‚¹ãƒ¼ãƒ‘ãƒ¼ã€ã¨ã„ã†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§è‡ªå®…ã«æœ€ã‚‚è¿‘ã„å ´æ‰€ã‚’æ¤œç´¢ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚`maps_search_places`ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
2. **è©³ç´°æƒ…å ±ã®å–å¾—:** æ¬¡ã«ã€è¦‹ã¤ã‹ã£ãŸã‚¹ãƒ¼ãƒ‘ãƒ¼ãŒã€Œåˆå¾Œ3æ™‚ã€ã«å–¶æ¥­ã—ã¦ã„ã‚‹ã‹ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚`maps_place_details`ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ã€å ´æ‰€ã®IDï¼ˆplace_idï¼‰ã‹ã‚‰å–¶æ¥­æ™‚é–“ãªã©ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã€‚
3. **ãƒ«ãƒ¼ãƒˆã®ç¢ºèª:** æœ€å¾Œã«ã€è‡ªå®…ã‹ã‚‰ãã®ã‚¹ãƒ¼ãƒ‘ãƒ¼ã¾ã§ã®å…·ä½“çš„ãªé“é †ã¨æ‰€è¦æ™‚é–“ã‚’èª¿ã¹ã‚‹ã€‚`maps_directions`ãƒ„ãƒ¼ãƒ«ã§ã€è‡ªå®…ã‹ã‚‰ã‚¹ãƒ¼ãƒ‘ãƒ¼ã¾ã§ã®ãƒ«ãƒ¼ãƒˆã‚’æ¤œç´¢ã™ã‚‹ã€‚
ã“ã‚Œã‚‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’é †ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è²·ã„ç‰©è¨ˆç”»ã‚’ã‚µãƒãƒ¼ãƒˆã§ãã‚‹ã€‚

# æœ¬ç•ª
### question
{question}
### answer
{answer}
### thinking
"""

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---

def load_input_data(path: Path) -> list[dict]:
    """
    æ–°ã—ã„å½¢å¼ã®JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å‡¦ç†ç”¨ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹ã€‚
    """
    data = []
    try:
        with open(path, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    entry = json.loads(line)
                    messages = entry.get('messages', [])
                    if len(messages) >= 2 and messages[0]['role'] == 'user' and messages[1]['role'] == 'assistant':
                        user_msg = messages[0]
                        assistant_msg = messages[1]

                        question = user_msg.get('content')
                        tool_calls = assistant_msg.get('tool_calls')

                        if question and isinstance(tool_calls, list):
                            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã« tool_calls ã‚’ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆä»˜ãã®JSONæ–‡å­—åˆ—ã«å¤‰æ›
                            answer_str = json.dumps(tool_calls, ensure_ascii=False, indent=2)
                            data.append({
                                'question': question,
                                'answer_str': answer_str, # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã®æ–‡å­—åˆ—
                                'original_entry': entry   # å…ƒã®ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã‚’ä¿æŒ
                            })
                except (json.JSONDecodeError, KeyError, IndexError):
                    print(f"Warning: Skipping malformed or unexpected JSON line: {line.strip()}")
                    continue
    except FileNotFoundError:
        print(f"Error: Input file not found at {path}")
        return []
    return data

def clean_llm_output(text: str) -> str:
    """LLMã®å‡ºåŠ›ã‹ã‚‰ä¸è¦ãªç©ºç™½ã‚„æ¥é ­è¾ã‚’å‰Šé™¤ã™ã‚‹"""
    text = text.strip()
    text = re.sub(r'^(thinking|æ€è€ƒ|æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹)\s*[:ï¼š]\s*', '', text, flags=re.IGNORECASE)
    return text.strip()


# --- ãƒ¯ãƒ¼ã‚«ãƒ¼é–¢æ•° ---

def generate_thinking_worker(item: dict, host: str):
    """
    1ã¤ã®ãƒ‡ãƒ¼ã‚¿é …ç›®ã‹ã‚‰thinkingã‚’ç”Ÿæˆã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼ã€‚
    """
    prompt_for_llm = THINKING_GENERATION_PROMPT_TEMPLATE.format(
        question=item['question'],
        answer=item['answer_str']
    )

    attempts = 0
    while attempts < MAX_ATTEMPTS:
        try:
            response = requests.post(
                f"http://{host}/api/chat",
                json={
                    "model": MODEL_NAME,
                    "messages": [{"role": "user", "content": prompt_for_llm}],
                    "stream": False
                },
                timeout=240
            )
            response.raise_for_status()
            generated_text = response.json().get("message", {}).get("content", "")
            cleaned_thinking = clean_llm_output(generated_text)

            if cleaned_thinking:
                # æˆåŠŸã—ãŸã‚‰ã€ç”Ÿæˆã—ãŸæ€è€ƒã¨å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
                return {
                    'thinking': cleaned_thinking,
                    'original_entry': item['original_entry'],
                    'status': 'success'
                }
            else:
                attempts += 1
                print(f"Warning: Empty response from {host}. Retrying ({attempts}/{MAX_ATTEMPTS})...")
                time.sleep(2)

        except requests.exceptions.RequestException as e:
            attempts += 1
            print(f"Error on {host}: {e}. Retrying ({attempts}/{MAX_ATTEMPTS})...")
            time.sleep(5)

    # å…¨ã¦ã®ãƒªãƒˆãƒ©ã‚¤ãŒå¤±æ•—ã—ãŸå ´åˆ
    return {
        'thinking': None,
        'original_entry': item['original_entry'],
        'status': 'failed'
    }


# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯ ---

def main():
    OUTPUT_JSONL_PATH.parent.mkdir(parents=True, exist_ok=True)
    gpu_ports = [f"127.0.0.1:{BASE_PORT + i}" for i in range(NUM_GPUS)]

    print(f"ğŸ”„ Loading data from {INPUT_JSONL_PATH}...")
    tasks_to_process = load_input_data(INPUT_JSONL_PATH)
    if not tasks_to_process:
        print("âŒ No valid tasks to process. Exiting.")
        return
    print(f"âœ… Loaded {len(tasks_to_process)} tasks.")

    print(f"ğŸ¤– Starting 'thinking' generation for {len(tasks_to_process)} tasks using {NUM_GPUS} workers...")
    all_results = []
    with ThreadPoolExecutor(max_workers=NUM_GPUS * 16) as executor:
        futures = {
            executor.submit(generate_thinking_worker, task, gpu_ports[i % NUM_GPUS]): task
            for i, task in enumerate(tasks_to_process)
        }
        with tqdm(total=len(tasks_to_process), desc="ğŸ¤” Generating Thinking") as pbar:
            for future in as_completed(futures):
                result = future.result()
                all_results.append(result)
                pbar.update(1)

    # â˜…â˜…â˜…ã€å¤‰æ›´ç®‡æ‰€ã€‘â˜…â˜…â˜…
    # 3. çµæœã®é›†è¨ˆã¨ã€æŒ‡å®šã•ã‚ŒãŸæ§‹é€ ã§ã®ä¿å­˜
    successful_results = [res for res in all_results if res['status'] == 'success']
    failed_count = len(all_results) - len(successful_results)

    print(f"\nâœï¸ Writing {len(successful_results)} successful results to {OUTPUT_JSONL_PATH}...")
    with open(OUTPUT_JSONL_PATH, "w", encoding="utf-8") as f:
        for result in successful_results:
            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            entry_to_write = result['original_entry']
            
            # assistantãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®contentã‚’ç”Ÿæˆã—ãŸthinkingã§æ›´æ–°
            # entry_to_write['messages'][1]ãŒassistantãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã‚ã‚‹ã¨æƒ³å®š
            assistant_message = entry_to_write['messages'][1]
            assistant_message['content'] = result['thinking']
            
            f.write(json.dumps(entry_to_write, ensure_ascii=False) + '\n')

    print("\n--- âœ¨ Generation Complete! âœ¨ ---")
    print(f"âœ”ï¸ Successful: {len(successful_results)}")
    print(f"âŒ Failed:     {failed_count}")
    print(f"ğŸ“„ Output file: {OUTPUT_JSONL_PATH}")
    print("ğŸ‰ All done.")

if __name__ == "__main__":
    main()
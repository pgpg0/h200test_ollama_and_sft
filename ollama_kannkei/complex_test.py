import os
import re
import pandas as pd
import json
from pathlib import Path
from langdetect import detect, LangDetectException
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from tqdm import tqdm

# --- è¨­å®šé …ç›® ---
INPUT_DIR = Path('/home/ubuntu/client/Data_azami/input_data')
OUTPUT_DIR = Path('/home/ubuntu/client/Data_azami/result')
MAX_ATTEMPTS = 10

# --- LangChainè¨­å®š ---
llm = ChatOllama(model="wao/DeepSeek-R1-Distill-Qwen-32B-Japanese")

prompt = ChatPromptTemplate.from_messages([
    ("system", "ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
    ("user", """
ä»¥ä¸‹ã®å•†å“æ¦‚è¦ã‚’èª­ã¿ã€é¡§å®¢ã‹ã‚‰ã®å•ã„åˆã‚ã›ä¾‹ã‚’Q&Aå½¢å¼ã§3ã¤ä½œæˆã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®å›ç­”å½¢å¼ã«å¾“ã£ã¦ä½œæˆã—ã¦ãã ã•ã„ã€‚

### è£½å“æƒ…å ±
{product_info}

### å›ç­”å½¢å¼
Q1:
A1:
Q2:
A2:
Q3:
A3:
""")
])

chain = prompt | llm | StrOutputParser()

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤ (å¤‰æ›´ãªã—) ---

def clean_llm_output(text: str) -> str:
    """LLMã®å‡ºåŠ›ã‹ã‚‰ä½™è¨ˆãªãƒ˜ãƒƒãƒ€ãƒ¼ã‚„ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’å‰Šé™¤ã™ã‚‹"""
    text = re.sub(r'<think>.*?</think>\s*', '', text, flags=re.DOTALL)
    text = re.sub(r'### (è£½å“æƒ…å ±|å›ç­”å½¢å¼).*?(\n|$)', '', text, flags=re.DOTALL)
    text = re.sub(r'^\s*#+\s*', '', text, flags=re.MULTILINE)
    return text.strip()

def parse_qa_text(text: str) -> dict | None:
    """Q&Aãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æã—ã¦è¾æ›¸ã«å¤‰æ›ã™ã‚‹"""
    qa_pairs = {}
    pattern = re.compile(r"(Q[1-3]):\s*(.*?)\s*(A[1-3]):\s*(.*?)(\n(?=Q[1-3]|$)|$)", re.DOTALL)
    matches = pattern.findall(text)
    
    if len(matches) != 3:
        return None

    for q_label, q_text, a_label, a_text, _ in matches:
        qa_pairs[q_label] = q_text.strip()
        qa_pairs[a_label] = a_text.strip()
        
    if all(k in qa_pairs for k in ["Q1", "A1", "Q2", "A2", "Q3", "A3"]):
        return qa_pairs
    return None

def is_qa_valid(qa_dict: dict) -> bool:
    """è§£æã•ã‚ŒãŸQ&Aè¾æ›¸ãŒæœ‰åŠ¹ã‹ï¼ˆè¨€èªãƒã‚§ãƒƒã‚¯ã‚’å«ã‚€ï¼‰ã‚’æ¤œè¨¼ã™ã‚‹"""
    if not qa_dict:
        return False
    try:
        for i in range(1, 4):
            answer = qa_dict.get(f"A{i}")
            if not answer or detect(answer) != 'ja':
                return False
    except LangDetectException:
        return False
    return True

# --- ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–¢æ•° (å…¥åŠ›ã¨å‡ºåŠ›ã®ãƒ‘ã‚¹ã‚’å¼•æ•°ã§å—ã‘å–ã‚‹ã‚ˆã†ã«å¤‰æ›´) ---

def generate_qa_from_csv(csv_path: Path, output_json_path: Path):
    """
    å˜ä¸€ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã€æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã«JSONçµæœã‚’å‡ºåŠ›ã™ã‚‹é–¢æ•°
    """
    try:
        df = pd.read_csv(csv_path)
    except FileNotFoundError:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        return

    all_results = []
    
    # tqdmã§å‡¦ç†ã®é€²æ—ã‚’è¡¨ç¤º
    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=f"Processing {csv_path.name}"):
        product_name = row['å•†å“å']
        product_info = f"å•†å“å: {row['å•†å“å']}\nã‚«ãƒ†ã‚´ãƒª: {row['å•†å“ã‚«ãƒ†ã‚´ãƒª']}\nç‰¹å¾´: {row['ç‰¹å¾´']}"
        
        result_data = {
            "product_name": product_name,
            "category": row['å•†å“ã‚«ãƒ†ã‚´ãƒª'],
            "features": row['ç‰¹å¾´'],
            "status": "failed",
            "attempts": 0,
            "qa_pairs": None,
            "last_raw_response": None,
        }
        
        is_valid = False
        attempts = 0

        while not is_valid and attempts < MAX_ATTEMPTS:
            attempts += 1
            result_data["attempts"] = attempts
            
            try:
                raw_response = chain.invoke({"product_info": product_info})
                result_data["last_raw_response"] = raw_response
                cleaned_text = clean_llm_output(raw_response)
                parsed_qa = parse_qa_text(cleaned_text)
                
                if is_qa_valid(parsed_qa):
                    is_valid = True
                    result_data["status"] = "success"
                    result_data["qa_pairs"] = parsed_qa
                else:
                    # å¤±æ•—æ™‚ã¯ãƒ«ãƒ¼ãƒ—ã‚’ç¶™ç¶šï¼ˆæœ€çµ‚è©¦è¡Œã§ãªã‘ã‚Œã°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯çœç•¥ï¼‰
                    if attempts == MAX_ATTEMPTS:
                         print(f"\n  -> âŒ [{product_name}] æ¤œè¨¼å¤±æ•— (æœ€çµ‚è©¦è¡Œ)")
            except Exception as e:
                print(f"\n  -> âŒ [{product_name}] ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                result_data["last_raw_response"] = str(e)
                break # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯ãã®è£½å“ã®è©¦è¡Œã‚’ä¸­æ­¢
        
        all_results.append(result_data)

    try:
        with open(output_json_path, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… å‡¦ç†å®Œäº†ã€‚çµæœã‚’ {output_json_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"\nğŸš¨ JSONãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯ ---
if __name__ == "__main__":
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    csv_files = list(INPUT_DIR.glob('*.csv'))
    
    if not csv_files:
        print(f"å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ {INPUT_DIR} ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    else:
        print(f"{len(csv_files)}å€‹ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¾ã™ã€‚")
        for csv_file_path in csv_files:
            print(f"\n{'='*60}\nå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™: {csv_file_path.name}\n{'='*60}")
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ (ä¾‹: input.csv -> input_qa_results.json)
            output_file_path = OUTPUT_DIR / f"{csv_file_path.stem}_qa_results.json"
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«å‡¦ç†ã‚’å®Ÿè¡Œ
            generate_qa_from_csv(csv_file_path, output_file_path)
            
        print(f"\n{'='*60}\nã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n{'='*60}")